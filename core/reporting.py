# -*- coding: utf-8 -*-
"""
core.reporting â€” HTML/Markdown æŠ¥å‘Šç”Ÿæˆ
"""
from __future__ import annotations
import json, base64, logging
from pathlib import Path
from typing import Dict, Any, List

# ---------- è¿è¡Œè®°å½•è¿­ä»£ ----------
def _rec_path(run_dir: str) -> Path:
    """è·å–è®°å½•æ–‡ä»¶è·¯å¾„"""
    return Path(run_dir) / "run.jsonl"

def _iter_run_records(run_dir: str):
    """è¿­ä»£è¿è¡Œè®°å½•"""
    p = _rec_path(run_dir)
    if not p.exists():
        return
    for ln in p.read_text("utf-8", errors="ignore").splitlines():
        try:
            yield json.loads(ln)
        except:
            continue

def summarize_run(run_dir: str) -> Dict[str, Any]:
    """æ±‡æ€»è¿è¡Œç»Ÿè®¡"""
    total = 0
    has_subs = 0
    no_subs = 0
    errors = 0
    err_kinds = {}
    lang_counts = {"zh": 0, "en": 0, "other": 0}
    videos = []
    
    for r in _iter_run_records(run_dir):
        total += 1
        st = r.get("status", "")
        if st == "has_subs":
            has_subs += 1
        elif st == "no_subs":
            no_subs += 1
        elif str(st).startswith("error"):
            errors += 1
            err_kinds[st] = err_kinds.get(st, 0) + 1
        
        for lc in (r.get("manual_langs") or []) + (r.get("auto_langs") or []):
            b = "zh" if str(lc).lower().startswith(("zh", "cmn")) else "en" if str(lc).lower().startswith("en") else "other"
            lang_counts[b] += 1
        
        videos.append({
            "video_id": r.get("video_id"),
            "title": r.get("title"),
            "channel": r.get("channel"),
            "upload_date": r.get("upload_date"),
            "status": st
        })
    
    return {
        "run_dir": run_dir,
        "total": total,
        "has_subs": has_subs,
        "no_subs": no_subs,
        "errors": errors,
        "error_breakdown": err_kinds,
        "lang_counts": lang_counts,
        "videos": videos
    }

def generate_report_charts(run_dir: str) -> List[str]:
    """ç”ŸæˆæŠ¥å‘Šå›¾è¡¨ï¼ˆå¯é€‰ï¼Œéœ€è¦ matplotlibï¼‰"""
    try:
        import matplotlib
        matplotlib.use("Agg")
        import matplotlib.pyplot as plt
    except Exception as e:
        logging.warning(f"Matplotlib not available: {e}")
        return []
    
    sm = summarize_run(run_dir)
    out_paths = []
    
    # é”™è¯¯é¥¼å›¾ï¼ˆä¿æŠ¤ï¼šå…¨é›¶æ—¶ä½¿ç”¨å ä½ï¼Œé¿å… RuntimeWarning/DivideByZeroï¼‰
    labels = list(sm["error_breakdown"].keys()) or ["no_error"]
    sizes = [sm["error_breakdown"].get(k, 0) for k in labels]
    if not sizes or sum(sizes) <= 0:
        labels, sizes = ["no_error"], [1]
    fig = plt.figure()
    plt.pie(sizes, labels=labels, autopct="%1.1f%%")
    p1 = str(Path(run_dir) / "chart_errors_pie.png")
    fig.savefig(p1, bbox_inches="tight", dpi=144)
    plt.close(fig)
    out_paths.append(p1)
    
    # è¯­è¨€æŸ±çŠ¶å›¾
    langs = ["zh", "en", "other"]
    vals = [sm["lang_counts"].get(k, 0) for k in langs]
    fig = plt.figure()
    plt.bar(langs, vals)
    plt.title("Language Counts")
    p2 = str(Path(run_dir) / "chart_lang_bar.png")
    fig.savefig(p2, bbox_inches="tight", dpi=144)
    plt.close(fig)
    out_paths.append(p2)
    
    # ç»“æœæŸ±çŠ¶å›¾
    metrics = ["has_subs", "no_subs", "errors"]
    mvals = [sm.get("has_subs", 0), sm.get("no_subs", 0), sm.get("errors", 0)]
    fig = plt.figure()
    plt.bar(metrics, mvals)
    plt.title("Result Breakdown")
    p3 = str(Path(run_dir) / "chart_results_bar.png")
    fig.savefig(p3, bbox_inches="tight", dpi=144)
    plt.close(fig)
    out_paths.append(p3)
    
    return out_paths

def export_run_html(run_dir: str) -> str:
    """
    ç”Ÿæˆ HTML æŠ¥å‘Š
    
    è¿”å›æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    try:
        sm = summarize_run(run_dir)
    except Exception:
        return ""
    
    try:
        generate_report_charts(run_dir)
    except Exception:
        pass
    
    def _embed(name: str) -> str:
        """åµŒå…¥å›¾ç‰‡ä¸º base64"""
        fp = Path(run_dir) / name
        if not fp.exists(): 
            return f"<p>{name}ï¼ˆæœªç”Ÿæˆï¼‰</p>"
        try:
            b64 = base64.b64encode(fp.read_bytes()).decode("ascii")
            return f'<img alt="{name}" src="data:image/png;base64,{b64}" style="max-width: 320px; margin: 6px;"/>'
        except Exception:
            return f"<p>{name}ï¼ˆæ— æ³•è¯»å–ï¼‰</p>"
    
    charts = "".join(_embed(n) for n in ("chart_errors_pie.png", "chart_lang_bar.png", "chart_results_bar.png"))
    
    # è¯Šæ–­æ‘˜è¦ï¼ˆé¡¶éƒ¨ä¼˜å…ˆå±•ç¤ºï¼‰
    diag_html = ""
    diag_path = Path(run_dir) / "diagnose.txt"
    if diag_path.exists():
        try:
            diag_lines = diag_path.read_text("utf-8", errors="ignore").splitlines()[:30]
            diag_text = "\n".join(diag_lines)
            diag_html = f"<pre style='background:#f5f5f5;padding:12px;border-radius:6px;overflow:auto;max-width:100%;'>{diag_text}</pre>"
        except Exception:
            pass
    
    # è­¦å‘Šä¿¡æ¯
    warn_path = Path(run_dir) / "warnings.txt"
    if warn_path.exists():
        lines = [ln.strip() for ln in warn_path.read_text("utf-8", errors="ignore").splitlines() if ln.strip()]
        total_warns = len(lines)
        warn_html = (
            f"<p>å…± {total_warns} æ¡å‘Šè­¦</p>" +
            ("<ul>" + "".join(f"<li>{ln}</li>" for ln in lines[:200]) + "</ul>" if lines else "<p>æ— å‘Šè­¦</p>")
        )
    else:
        warn_html = "<p>æ— å‘Šè­¦</p>"
    
    # è§†é¢‘è¡¨æ ¼
    def td(x):
        from html import escape
        return f"<td>{escape(str(x if x is not None else ''))}</td>"
    
    rows = []
    for v in sm.get("videos", [])[:300]:
        rows.append("<tr>" + td(v.get("upload_date")) + td(v.get("status")) + td(v.get("title")) + td(v.get("video_id")) + "</tr>")
    table_html = "<table border='1' cellspacing='0' cellpadding='6'><tr><th>upload_date</th><th>status</th><th>title</th><th>video_id</th></tr>" + "".join(rows) + "</table>"
    
    # AI å¡ç‰‡ï¼ˆä¸Šé™ 50 æ¡ï¼‰
    ai_dir = Path(run_dir) / "ai"
    ai_cards = ""
    try:
        if ai_dir.exists():
            all_json = sorted(ai_dir.glob("*.json"))
            total_ai = len(all_json)
            cards = []
            for j in all_json[:50]:
                try:
                    data = json.loads(j.read_text("utf-8"))
                    title = ""
                    for v in sm.get("videos", []):
                        if v.get("video_id") == data.get("video_id"):
                            title = v.get("title") or ""
                            break
                    brief = (data.get("summary") or "")[:160].replace("\n", " ")
                    kws = ", ".join(data.get("keywords") or [])[:120]
                    chapters = data.get("chapters") or []
                    ch_html = ""
                    if chapters:
                        li = []
                        for c in chapters:
                            li.append(f"<li>[{c.get('start','00:00:00')}] {c.get('title','')}</li>")
                        ch_html = "<ul style='margin-top:6px'>" + "".join(li) + "</ul>"
                    cards.append(f"<div style='border:1px solid #ddd;border-radius:8px;padding:10px;margin:6px;max-width:720px;'><b>{title or data.get('video_id')}</b><br/><div style='margin-top:6px;font-size:13px;line-height:1.5;'>{brief}</div><div style='margin-top:6px;color:#555;'>ğŸ”‘ {kws}</div>{ch_html}</div>")
                except Exception:
                    continue
            if cards:
                header = f"<h3>AI æ‘˜è¦ï¼ˆå±•ç¤º {len(cards)}/{total_ai} æ¡ï¼‰</h3>"
                if total_ai > 50:
                    header += f"<p style='color:#666;'>ï¼ˆå…± {total_ai} æ¡ï¼Œä»…å±•ç¤ºå‰ 50 æ¡ï¼‰</p>"
                ai_cards = header + "".join(cards)
    except Exception:
        pass
    
    html = f"""<!doctype html>
<html><head><meta charset="utf-8"><title>Run Report</title></head>
<body style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial; padding: 12px;">
<h2>è¿è¡ŒæŠ¥å‘Š</h2>
<p>ç›®å½•ï¼š{run_dir}</p>
<h3>ğŸ“Š è¯Šæ–­æ‘˜è¦</h3>
{diag_html if diag_html else "<p>æ— è¯Šæ–­æŠ¥å‘Š</p>"}
<h3>âš ï¸ Warnings</h3>
{warn_html}
<p>æ€»æ•°ï¼š{sm.get('total',0)}ï¼›æœ‰å­—å¹•ï¼š{sm.get('has_subs',0)}ï¼›æ— å­—å¹•ï¼š{sm.get('no_subs',0)}ï¼›é”™è¯¯ï¼š{sm.get('errors',0)}</p>
<div style="display:flex; flex-wrap: wrap;">{charts}</div>
{ai_cards}
<h3>æ˜ç»†ï¼ˆæœ€å¤š 300 æ¡ï¼‰</h3>
{table_html}
</body></html>"""
    
    try:
        out = Path(run_dir) / "report.html"
        out.write_text(html, encoding="utf-8")
        return str(out)
    except Exception:
        return ""

def export_weekly_markdown(out_root: str, days: int = 7) -> str:
    """
    ç”Ÿæˆå‘¨æŠ¥ Markdownï¼ˆæ±‡æ€»è¿‘ N å¤©çš„æ‰€æœ‰è¿è¡Œï¼‰
    
    è¿”å›æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    import os
    from datetime import datetime, timedelta
    
    # æ‰¾åˆ°æ‰€æœ‰è¿è¡Œç›®å½•
    out_path = Path(out_root)
    if not out_path.exists():
        return ""
    
    cutoff_date = datetime.now() - timedelta(days=days)
    runs = []
    
    for d in out_path.iterdir():
        if not d.is_dir() or not d.name.startswith("run_"):
            continue
        try:
            # è§£æç›®å½•åæ—¶é—´æˆ³
            ts_str = d.name.replace("run_", "")
            run_dt = datetime.strptime(ts_str[:14], "%Y%m%d%H%M%S")
            if run_dt >= cutoff_date:
                runs.append((run_dt, d))
        except Exception:
            continue
    
    if not runs:
        return ""
    
    runs.sort(reverse=True)  # æœ€æ–°çš„åœ¨å‰
    
    # ç´¯è®¡ç»Ÿè®¡
    total_all = 0
    has_subs_all = 0
    no_subs_all = 0
    errors_all = 0
    err_kinds_all = {}
    lang_counts_all = {"zh": 0, "en": 0, "other": 0}
    
    run_summaries = []
    for run_dt, run_dir in runs:
        sm = summarize_run(str(run_dir))
        total_all += sm.get("total", 0)
        has_subs_all += sm.get("has_subs", 0)
        no_subs_all += sm.get("no_subs", 0)
        errors_all += sm.get("errors", 0)
        
        for k, v in sm.get("error_breakdown", {}).items():
            err_kinds_all[k] = err_kinds_all.get(k, 0) + v
        
        for k, v in sm.get("lang_counts", {}).items():
            lang_counts_all[k] = lang_counts_all.get(k, 0) + v
        
        run_summaries.append({
            "run_dir": run_dir.name,
            "date": run_dt.strftime("%Y-%m-%d %H:%M"),
            "total": sm.get("total", 0),
            "has_subs": sm.get("has_subs", 0),
            "errors": sm.get("errors", 0)
        })
    
    # ç”Ÿæˆ Markdown
    md = f"""# å‘¨æŠ¥ï¼ˆè¿‘ {days} å¤©ï¼‰

**ç”Ÿæˆæ—¶é—´**ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š æ€»ä½“ç»Ÿè®¡

- **ç´¯è®¡è¿è¡Œ**ï¼š{len(runs)} æ¬¡
- **ç´¯è®¡è§†é¢‘**ï¼š{total_all} ä¸ª
- **æœ‰å­—å¹•**ï¼š{has_subs_all} ä¸ª
- **æ— å­—å¹•**ï¼š{no_subs_all} ä¸ª
- **é”™è¯¯**ï¼š{errors_all} ä¸ª

## ğŸŒ è¯­è¨€åˆ†å¸ƒ

- **ä¸­æ–‡**ï¼š{lang_counts_all.get('zh', 0)} ä¸ª
- **è‹±æ–‡**ï¼š{lang_counts_all.get('en', 0)} ä¸ª
- **å…¶ä»–**ï¼š{lang_counts_all.get('other', 0)} ä¸ª

## âŒ é”™è¯¯ç±»å‹åˆ†å¸ƒ

"""
    for k, v in sorted(err_kinds_all.items(), key=lambda x: x[1], reverse=True):
        md += f"- **{k}**ï¼š{v} æ¬¡\n"
    
    md += "\n## ğŸ“ è¿è¡Œè®°å½•\n\n"
    md += "| æ—¥æœŸ | è¿è¡Œç›®å½• | æ€»æ•° | æœ‰å­—å¹• | é”™è¯¯ |\n"
    md += "|------|----------|------|--------|------|\n"
    
    for rs in run_summaries:
        md += f"| {rs['date']} | {rs['run_dir']} | {rs['total']} | {rs['has_subs']} | {rs['errors']} |\n"
    
    # ä¿å­˜
    try:
        out_file = out_path / f"weekly_report_{datetime.now().strftime('%Y%m%d')}.md"
        out_file.write_text(md, encoding="utf-8")
        return str(out_file)
    except Exception:
        return ""

def export_run_md(run_dir: str) -> str:
    """
    ç”Ÿæˆ Markdown æŠ¥å‘Š
    
    è¿”å›æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    sm = summarize_run(run_dir)
    lines = [f"# Run Report - {Path(run_dir).name}", ""]
    lines += [
        f"- total: {sm.get('total',0)}",
        f"- has_subs: {sm.get('has_subs',0)}",
        f"- no_subs: {sm.get('no_subs',0)}",
        f"- errors: {sm.get('errors',0)}",
        ""
    ]
    
    ai_dir = Path(run_dir) / "ai"
    if ai_dir.exists():
        lines.append("## AI Summaries")
        for j in sorted(ai_dir.glob("*.json"))[:50]:
            try:
                data = json.loads(j.read_text("utf-8"))
                title = data.get("video_id", "")
                for v in sm.get("videos", []):
                    if v.get("video_id") == data.get("video_id"):
                        title = v.get("title") or title
                        break
                lines.append(f"### {title}")
                if data.get("summary"): 
                    lines.append(data["summary"][:600] + ("â€¦" if len(data["summary"]) > 600 else ""))
                if data.get("keywords"): 
                    lines.append("- **Keywords**: " + ", ".join(data["keywords"][:15]))
                if data.get("chapters"):
                    lines.append("- **Chapters**:")
                    for c in data["chapters"]:
                        lines.append(f"  - [{c.get('start','00:00:00')}] {c.get('title','')}")
                lines.append("")
            except Exception:
                continue
    
    out = Path(run_dir) / "report.md"
    out.write_text("\n".join(lines) + "\n", encoding="utf-8")
    return str(out)

